{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQ0ZvGRqenPf"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gen Media on Vertex AI\n",
        "\n",
        "Welcome to Gen Media on VertexAI! This notebook offers sample code on:\n",
        "- Character Generation: Nano Banana\n",
        "- Scripting the scenes: Gemini\n",
        "- Generating the video: Veo 3\n",
        "\n",
        "Each example is designed to be clear, easy to follow, and adaptable for your own projects, demonstrating a specific capability of the model."
      ],
      "metadata": {
        "id": "uBRWqsH2e88Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Authors |\n",
        "| --- |\n",
        "| [Laxmi Harikumar](https://github.com/laxmi-genai) |\n",
        "| [Vlad Kolesnikov](https://github.com/https://github.com/vladkol/) |"
      ],
      "metadata": {
        "id": "dKhcr1PifIqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Setup\n",
        "\n",
        "Begin by installing the required Python packages for the notebook."
      ],
      "metadata": {
        "id": "FoYf4jQ_gzeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet google-genai pillow"
      ],
      "metadata": {
        "id": "twd9NaLye0th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you're running this notebook on Google Colab, run the cell below to authenticate your environment."
      ],
      "metadata": {
        "id": "iR2nQq53g4lP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ],
      "metadata": {
        "id": "Gsc5jim1g-Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure Google Cloud Project\n",
        "\n",
        "To use Vertex AI, you need a Google Cloud project with the [Vertex AI API enabled](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "For more details, see the documentation on [setting up a project and development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ],
      "metadata": {
        "id": "H2C4VGDThA37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the environment variable if the user doesn't provide Project ID.\n",
        "import os\n",
        "\n",
        "# fmt: off\n",
        "PROJECT_ID = \"\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "# fmt: on\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = \"global\"\n",
        "\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "WR4kcloDhGbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Generation with Nano Banana!"
      ],
      "metadata": {
        "id": "0FKheYsshTF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Do the required imports"
      ],
      "metadata": {
        "id": "JV6x6eg9hzAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "from google.genai import types\n",
        "\n",
        "import base64\n",
        "import time\n",
        "from IPython.display import Video, Markdown"
      ],
      "metadata": {
        "id": "yDR-woYyh169"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions and Utilities\n",
        "\n",
        "This section contains the helper functions that will be used throughout the notebook to streamline image generation and processing tasks."
      ],
      "metadata": {
        "id": "nkAOiCuAhiBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_model = \"veo-3.1-generate-preview\"\n",
        "gemini_model = \"gemini-2.5-flash\""
      ],
      "metadata": {
        "id": "FlbodYIqbfhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_video(video):\n",
        "    if isinstance(video, str):\n",
        "        file_name = video.split(\"/\")[-1]\n",
        "        !gsutil cp {video} {file_name}\n",
        "        display(Video(file_name, embed=True, width=600, height=400))\n",
        "    else:\n",
        "        with open(\"sample.mp4\", \"wb\") as out_file:\n",
        "            out_file.write(video)\n",
        "        display(Video(\"sample.mp4\", embed=True, width=600, height=400))"
      ],
      "metadata": {
        "id": "8vqVQ17LbppE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 1: Generate an Image from Text Prompt\n",
        "\n",
        "We'll begin with a fundamental task: generating an image from a text prompt. Consider a scenario where you need to generate a menu for your restaurant."
      ],
      "metadata": {
        "id": "gjgAhkAiic3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Create a menu with 3 sections and with images of 3 of its plates:\n",
        "\n",
        "To start\n",
        "OYSTERS BY THE SHELL\n",
        "GARDEN TOMATO BRUSCHETTA\n",
        "BABY GREENS SALAD\n",
        "\n",
        "Main Dishes\n",
        "CITRUS CHICKEN\n",
        "GARLIC PRAWNS WITH LEMON\n",
        "PAN SEARED SEA BASS\n",
        "\n",
        "Desserts\n",
        "CHOCOLATE WEDDING CAKE\n",
        "ASSORTED LOCAL FRESH FRUITS\n",
        "AFFOGATO\n",
        "\"\"\"\n",
        "\n",
        "MODEL_NAME = \"gemini-2.5-flash-image\"\n",
        "GENERATION_CONFIG = types.GenerateContentConfig(\n",
        "    temperature=1,\n",
        "    top_p=0.95,\n",
        "    max_output_tokens=32768,\n",
        "    response_modalities=[\"TEXT\", \"IMAGE\"],\n",
        ")\n",
        "\n",
        "\n",
        "contents = [types.Content(role=\"user\",\n",
        "                          parts=[types.Part.from_text(text=prompt)])]\n",
        "\n",
        "print(\"Generating image from prompt...\")\n",
        "response = client.models.generate_content(\n",
        "        model=MODEL_NAME,\n",
        "        contents=contents,\n",
        "        config=GENERATION_CONFIG,\n",
        "    )\n",
        "\n",
        "if response.candidates and response.candidates[0].content.parts:\n",
        "    for part in response.candidates[0].content.parts:\n",
        "        if part.inline_data and part.inline_data.data:\n",
        "            display(Image.open(io.BytesIO(part.inline_data.data)))\n",
        "else:\n",
        "  print(\"No image was generated.\")"
      ],
      "metadata": {
        "id": "WyfwlzJJw8oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 2: Generate an Image from Text Prompt and an Image\n",
        "\n",
        "Chat with the data to modify the generated images!"
      ],
      "metadata": {
        "id": "I4wz-I49N7z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/images/speaker.png'\n",
        "\n",
        "prompt = \"\"\"Create a vibrant lifestyle photo. Place the reference speaker on a\n",
        "            picnic blanket in a park. A group of diverse, happy friends in\n",
        "            their 20s are laughing in the background, enjoying a sunny\n",
        "            afternoon. The scene should feel candid, warm, and full of life.\"\"\"\n",
        "\n",
        "\n",
        "with open(file_path, 'rb') as file:\n",
        "    image_bytes = file.read()\n",
        "\n",
        "image1 = types.Part.from_bytes(\n",
        "  data=image_bytes,\n",
        "  mime_type=\"image/png\",\n",
        ")"
      ],
      "metadata": {
        "id": "RilGRhwcnnPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"gemini-2.5-flash-image\"\n",
        "chat = client.chats.create(model=MODEL_NAME)\n",
        "\n",
        "response = chat.send_message(\n",
        "    message=[\n",
        "        image1,\n",
        "        prompt,\n",
        "    ],\n",
        "    config=types.GenerateContentConfig(\n",
        "        response_modalities=[\"IMAGE\"],\n",
        "        image_config=types.ImageConfig(\n",
        "            aspect_ratio=\"16:9\",\n",
        "        ),\n",
        "    ),\n",
        ")\n",
        "\n",
        "data = image1\n",
        "if response.candidates and response.candidates[0].content.parts:\n",
        "      for part in response.candidates[0].content.parts:\n",
        "        if part.inline_data and part.inline_data.data:\n",
        "          display(Image.open(io.BytesIO(part.inline_data.data)))\n",
        "          data = part.inline_data.data\n"
      ],
      "metadata": {
        "id": "dmDzA2K91IwA",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modification_prompt = \"\"\"Add a cheese tray and vegetables to the picnic food,\n",
        "  change the background and turn this into a picnic at the\n",
        "  beach on the sand during sunset.\"\"\"\n",
        "response = chat.send_message(\n",
        "    message=[\n",
        "        types.Part.from_bytes(\n",
        "            data=data,\n",
        "            mime_type=\"image/png\",\n",
        "        ),\n",
        "        modification_prompt,\n",
        "    ],\n",
        "    config=types.GenerateContentConfig(\n",
        "        response_modalities=[\"IMAGE\"],\n",
        "    ),\n",
        ")\n",
        "\n",
        "if response.candidates and response.candidates[0].content.parts:\n",
        "    for part in response.candidates[0].content.parts:\n",
        "      if part.inline_data and part.inline_data.data:\n",
        "        display(Image.open(io.BytesIO(part.inline_data.data)))\n",
        "        data = part.inline_data.data"
      ],
      "metadata": {
        "id": "mGtLrYct2TbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scene Generation with Gemini"
      ],
      "metadata": {
        "id": "RS2PGKWzbPG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 3: Generate the script with Gemini\n",
        "\n",
        "It is very important to detail the characters and the scenes\n",
        "Let's generate the script from the image?"
      ],
      "metadata": {
        "id": "JV1W8TsUOhZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "import base64\n",
        "import os\n",
        "\n",
        "def generate():\n",
        "\n",
        "  file_path = '/content/images/group_friends.png'\n",
        "\n",
        "  with open(file_path, 'rb') as file:\n",
        "      # .read() loads the entire file into memory as a 'bytes' object\n",
        "      image_bytes = file.read()\n",
        "\n",
        "  image1 = types.Part.from_bytes(\n",
        "    data=image_bytes,\n",
        "    mime_type=\"image/png\",\n",
        "  )\n",
        "\n",
        "\n",
        "  prompt = \"\"\"Generate detailed character profiles and scene details to create\n",
        "    a 8 second video for one scene - the people discussing their Paris trip with\n",
        "    just one dialogue. Provide the response as Markdown. Do not\n",
        "    use tables in the output. For each character generate a Name, Role,\n",
        "    Appearance, Personality and Wardrobe\"\"\"\n",
        "\n",
        "  model = \"gemini-2.5-flash\"\n",
        "  contents = [\n",
        "    types.Content(\n",
        "      role=\"user\",\n",
        "      parts=[\n",
        "        image1,\n",
        "        types.Part.from_text(text=prompt)\n",
        "      ]\n",
        "    )\n",
        "  ]\n",
        "  tools = [\n",
        "    types.Tool(google_search=types.GoogleSearch()),\n",
        "  ]\n",
        "\n",
        "  generate_content_config = types.GenerateContentConfig(\n",
        "    temperature = 1,\n",
        "    top_p = 0.95,\n",
        "    max_output_tokens = 65535,\n",
        "    safety_settings = [types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
        "      threshold=\"OFF\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "      threshold=\"OFF\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      threshold=\"OFF\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HARASSMENT\",\n",
        "      threshold=\"OFF\"\n",
        "    )],\n",
        "    tools = tools\n",
        "  )\n",
        "\n",
        "  response = client.models.generate_content(\n",
        "    model = model,\n",
        "    contents = contents,\n",
        "    config = generate_content_config,\n",
        "    )\n",
        "  return(response.candidates[0].content.parts[0].text)\n",
        "\n",
        "\n",
        "scene = generate()"
      ],
      "metadata": {
        "id": "z9nlWm_rJNXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(scene))"
      ],
      "metadata": {
        "id": "WVOhNRfwOMWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“Œ Make sure to review the content generated by Gemini and tweak it to match your narrative and ideas\n",
        "\n",
        "Create a prompt with the scene and the image generated"
      ],
      "metadata": {
        "id": "4ODibPPgSP11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_prompt = f\"\"\"\n",
        "You are an expert prompt engineer for Google's Veo model. Analyze the provided\n",
        "image and combine its content with the provided scene. Make sure to retain the\n",
        "character identities. Integrate the image's\n",
        "subject and scene with the requested motion and audio effects.\n",
        "The final output must be ONLY the prompt itself,\n",
        "with no preamble. Scene: {\",\".join(scene)}\n",
        "\"\"\"\n",
        "with open(\"/content/images/group_friends.png\", \"rb\") as f:\n",
        "    image = f.read()\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=gemini_model,\n",
        "    contents=[gemini_prompt, types.Part.from_bytes(data=image, mime_type=\"image/png\")],\n",
        ")\n",
        "\n",
        "# Set Gemini's response in a prompt variable\n",
        "prompt = response.text\n",
        "display(Markdown(response.text))\n"
      ],
      "metadata": {
        "id": "Jy-Og24aIdIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“Œ Make sure to review the prompt generated by Gemini and tweak it to match your narrative and ideas"
      ],
      "metadata": {
        "id": "IP61r32_TH9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 4: Generate the video with Veo3\n",
        "\n",
        "Generate the video with the prompt and a reference image"
      ],
      "metadata": {
        "id": "0xgGkaw7TK0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt = types.SubjectReferenceImageDict\n",
        "enhance_prompt = True  # @param {type: 'boolean'}\n",
        "generate_audio = True  # @param {type: 'boolean'}\n",
        "\n",
        "operation = client.models.generate_videos(\n",
        "    model=video_model,\n",
        "    prompt=prompt,\n",
        "    config=types.GenerateVideosConfig(\n",
        "        reference_images=[\n",
        "            types.VideoGenerationReferenceImage(\n",
        "                image=types.Image.from_file(location=\"/content/images/group_friends.png\"),\n",
        "                reference_type=\"asset\",\n",
        "            )\n",
        "        ],\n",
        "        aspect_ratio=\"16:9\",\n",
        "        number_of_videos=1,\n",
        "        duration_seconds=8,\n",
        "        resolution=\"1080p\",\n",
        "        person_generation=\"allow_adult\",\n",
        "        enhance_prompt=enhance_prompt,\n",
        "        generate_audio=generate_audio,\n",
        "    ),\n",
        ")\n",
        "\n",
        "while not operation.done:\n",
        "    time.sleep(15)\n",
        "    operation = client.operations.get(operation)\n",
        "    print(operation)\n",
        "\n",
        "if operation.response:\n",
        "    show_video(operation.result.generated_videos[0].video.video_bytes)"
      ],
      "metadata": {
        "id": "T3V6G3dxo8S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 5: Elevate the video with prompts\n",
        "\n",
        "Elevate your clip to a cinematic shot by directing the camera and ambiance."
      ],
      "metadata": {
        "id": "VcBRlsAjUMgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"A car driving in the city at night.\"\"\"\n",
        "\n",
        "\n",
        "operation = client.models.generate_videos(\n",
        "    model=video_model,\n",
        "    prompt=prompt,\n",
        "    config=types.GenerateVideosConfig(\n",
        "        aspect_ratio=\"16:9\",\n",
        "        number_of_videos=1,\n",
        "        duration_seconds=8,\n",
        "        resolution=\"1080p\",\n",
        "        person_generation=\"allow_adult\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "while not operation.done:\n",
        "    time.sleep(15)\n",
        "    operation = client.operations.get(operation)\n",
        "    print(operation)\n",
        "\n",
        "if operation.response:\n",
        "    show_video(operation.result.generated_videos[0].video.video_bytes)"
      ],
      "metadata": {
        "id": "2AA8ku4sUr3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"Cinematic wide shot of a vintage 1980s sports car, gleaming cherry\n",
        "red, speeding through a rain-slicked neon alley at night. The camera tracks\n",
        "smoothly alongside the car. Moody, high-contrast film noir lighting with\n",
        "reflections of pink and blue neon signs on the wet asphalt.\"\"\"\n",
        "\n",
        "enhance_prompt = True  # @param {type: 'boolean'}\n",
        "generate_audio = True  # @param {type: 'boolean'}\n",
        "\n",
        "operation = client.models.generate_videos(\n",
        "    model=video_model,\n",
        "    prompt=prompt,\n",
        "    config=types.GenerateVideosConfig(\n",
        "        aspect_ratio=\"16:9\",\n",
        "        number_of_videos=1,\n",
        "        duration_seconds=8,\n",
        "        resolution=\"1080p\",\n",
        "        person_generation=\"allow_adult\",\n",
        "        enhance_prompt=enhance_prompt,\n",
        "        generate_audio=generate_audio,\n",
        "    ),\n",
        ")\n",
        "\n",
        "while not operation.done:\n",
        "    time.sleep(15)\n",
        "    operation = client.operations.get(operation)\n",
        "    print(operation)\n",
        "\n",
        "if operation.response:\n",
        "    show_video(operation.result.generated_videos[0].video.video_bytes)"
      ],
      "metadata": {
        "id": "U3CI5MtrgeZM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}